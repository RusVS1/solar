{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error, r2_score\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"data/train.csv\"\n",
    "data = pd.read_csv(csv_file_path, sep=';', encoding='utf-8', index_col=False)\n",
    "\n",
    "numerical_columns = ['T', 'Po', 'U', 'Ff', 'sinα', 'Ho', 'ALLSKY_SFC_SW_DWN']\n",
    "\n",
    "for column in numerical_columns:\n",
    "    data[column] = data[column].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "data['MO'] = data['MO'].astype(int)\n",
    "data['DY'] = data['DY'].astype(int)\n",
    "\n",
    "data['DayOfYear'] = pd.to_datetime(\n",
    "    data[['YEAR', 'MO', 'DY']].astype(str).agg('-'.join, axis=1), errors='coerce'\n",
    ").dt.dayofyear.fillna(0).astype(int)\n",
    "\n",
    "data['sin_month'] = np.sin(2 * np.pi * data['MO'] / 12)\n",
    "data['cos_month'] = np.cos(2 * np.pi * data['MO'] / 12)\n",
    "\n",
    "data['sin_hour'] = np.sin(2 * np.pi * data['HR'] / 24)\n",
    "data['cos_hour'] = np.cos(2 * np.pi * data['HR'] / 24)\n",
    "data['sin_day_year'] = np.sin(2 * np.pi * data['DayOfYear'] / 365)\n",
    "data['cos_day_year'] = np.cos(2 * np.pi * data['DayOfYear'] / 365)\n",
    "\n",
    "features = ['sin_month', 'cos_month', 'sin_hour', 'cos_hour', 'sin_day_year', 'cos_day_year',\n",
    "            'T', 'Po', 'U', 'Ff', 'sinα', 'Ho']\n",
    "target = 'ALLSKY_SFC_SW_DWN'\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest...\n"
     ]
    }
   ],
   "source": [
    "# Обучение RandomForest\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "rf_r2 = r2_score(y_test, rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost...\n"
     ]
    }
   ],
   "source": [
    "# Обучение XGBoost\n",
    "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
    "xgb_r2 = r2_score(y_test, xgb_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1843\n",
      "[LightGBM] [Info] Number of data points in the train set: 107048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 147.017514\n"
     ]
    }
   ],
   "source": [
    "# Обучение LightGBM\n",
    "lgbm_model = LGBMRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "lgbm_pred = lgbm_model.predict(X_test)\n",
    "lgbm_mae = mean_absolute_error(y_test, lgbm_pred)\n",
    "lgbm_rmse = np.sqrt(mean_squared_error(y_test, lgbm_pred))\n",
    "lgbm_r2 = r2_score(y_test, lgbm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_model = LinearRegression()\n",
    "linreg_model.fit(X_train, y_train)\n",
    "linreg_pred = linreg_model.predict(X_test)\n",
    "linreg_mae = mean_absolute_error(y_test, linreg_pred)\n",
    "linreg_rmse = np.sqrt(mean_squared_error(y_test, linreg_pred))\n",
    "linreg_r2 = r2_score(y_test, linreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance:\n",
      "                    MAE       RMSE        R²\n",
      "RandomForest  25.127739  53.244435  0.938451\n",
      "XGBoost       26.023440  52.976058  0.939070\n",
      "LightGBM      26.062043  52.972918  0.939077\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Performance:\")\n",
    "results = {\n",
    "    'RandomForest': {'MAE': rf_mae, 'RMSE': rf_rmse, 'R²': rf_r2},\n",
    "    'XGBoost': {'MAE': xgb_mae, 'RMSE': xgb_rmse, 'R²': xgb_r2},\n",
    "    'LightGBM': {'MAE': lgbm_mae, 'RMSE': lgbm_rmse, 'R²': lgbm_r2},\n",
    "    'LinearRegressio': {'MAE': linreg_mae, 'RMSE': linreg_rmse, 'R²': linreg_r2},\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of rows: 8760\n",
      "Number of rows after transformations: 8760\n",
      "Predictions saved to predictions_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2500/101595467.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['RandomForest_Prediction'] = rf_pred\n",
      "/tmp/ipykernel_2500/101595467.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['XGBoost_Prediction'] = xgb_pred\n",
      "/tmp/ipykernel_2500/101595467.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  results['LightGBM_Prediction'] = lgbm_pred\n"
     ]
    }
   ],
   "source": [
    "test = \"test.csv\"\n",
    "data_test = pd.read_csv(test, sep=';', encoding='utf-8', index_col=False)\n",
    "print(f\"Original number of rows: {len(data_test)}\")\n",
    "\n",
    "num_columns = ['T', 'Po', 'U', 'Ff', 'sinα', 'Ho']\n",
    "for column in num_columns:\n",
    "    data_test[column] = data_test[column].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "data_test['MO'] = data_test['MO'].astype(int)\n",
    "data_test['DY'] = data_test['DY'].astype(int)\n",
    "\n",
    "data_test['DayOfYear'] = pd.to_datetime(\n",
    "    data_test[['YEAR', 'MO', 'DY']].astype(str).agg('-'.join, axis=1), errors='coerce'\n",
    ").dt.dayofyear.fillna(0).astype(int)\n",
    "\n",
    "data_test['sin_month'] = np.sin(2 * np.pi * data_test['MO'] / 12)\n",
    "data_test['cos_month'] = np.cos(2 * np.pi * data_test['MO'] / 12)\n",
    "\n",
    "data_test['sin_hour'] = np.sin(2 * np.pi * data_test['HR'] / 24)\n",
    "data_test['cos_hour'] = np.cos(2 * np.pi * data_test['HR'] / 24)\n",
    "data_test['sin_day_year'] = np.sin(2 * np.pi * data_test['DayOfYear'] / 365)\n",
    "data_test['cos_day_year'] = np.cos(2 * np.pi * data_test['DayOfYear'] / 365)\n",
    "\n",
    "features = ['sin_month', 'cos_month', 'sin_hour', 'cos_hour', 'sin_day_year', 'cos_day_year',\n",
    "            'T', 'Po', 'U', 'Ff', 'sinα', 'Ho']\n",
    "print(f\"Number of rows after transformations: {len(data_test)}\")\n",
    "\n",
    "X_test = data_test[features]\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "lgbm_pred = lgbm_model.predict(X_test)\n",
    "\n",
    "results = data_test[['YEAR', 'MO', 'DY', 'HR']]\n",
    "\n",
    "results['RandomForest_Prediction'] = rf_pred\n",
    "results['XGBoost_Prediction'] = xgb_pred\n",
    "results['LightGBM_Prediction'] = lgbm_pred\n",
    "\n",
    "output_file = 'predictions_output.csv'\n",
    "results.to_csv(output_file, index=False, sep=';')\n",
    "\n",
    "print(f\"Predictions saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
